name: E2E Tests
description: 'Runs end-to-end tests across different scenarios and JavaScript module types'

on:
  workflow_call:
    # Make this a reusable workflow, no value needed
    # https://docs.github.com/en/actions/using-workflows/reusing-workflows
    inputs:
      os:
        description: 'Operating system to run tests on'
        required: true
        type: string
      node-version:
        description: 'Node.js version to use for testing'
        required: true
        type: string
      build-command:
        description: 'Build command for test applications (build or build:mac-universal)'
        type: string
        default: 'build'
      scenario:
        description: 'Test scenario (forge, builder, or no-binary)'
        required: true
        type: string
      type:
        description: 'JavaScript module type (esm, cjs, or * for both)'
        type: string
        default: '*'
      build_id:
        description: 'Build ID from the build job'
        type: string
        required: false
      artifact_size:
        description: 'Size of the build artifact in bytes'
        type: string
        required: false
      cache_key:
        description: 'Cache key to use for downloading artifacts'
        type: string
        required: false

env:
  TURBO_TELEMETRY_DISABLED: 1

jobs:
  # This job runs E2E tests for a specific combination of:
  # - Operating system (Linux, Windows, macOS)
  # - Test scenario (builder, forge, no-binary)
  # - Module type (ESM, CJS, or both)
  e2e:
    name: E2E Tests
    runs-on: ${{ inputs.os }}
    strategy:
      # Continue with other tests even if one fails
      fail-fast: false
    steps:
      # Standard checkout with SSH key for private repositories
      - name: üë∑ Checkout Repository
        uses: actions/checkout@v4
        with:
          ssh-key: ${{ secrets.DEPLOY_KEY }}

      # Set up Node.js and PNPM using the reusable action
      - name: üõ†Ô∏è Setup Development Environment
        uses: ./.github/workflows/actions/setup-workspace
        with:
          node-version: ${{ inputs.node-version }}

      # Download the pre-built packages from the build job
      # This ensures all tests use the same build artifacts
      - name: üì¶ Download Build Artifacts
        uses: ./.github/workflows/actions/download-archive
        with:
          name: wdio-electron-service
          path: wdio-electron-service-build
          filename: artifact.zip
          cache_key_prefix: wdio-electron-build
          exact_cache_key: ${{ inputs.cache_key || github.run_id && format('{0}-{1}-{2}-{3}{4}', 'Linux', 'wdio-electron-build', 'wdio-electron-service', github.run_id, github.run_attempt > 1 && format('-rerun{0}', github.run_attempt) || '') || '' }}

      # Display build information if available
      - name: üìä Show Build Information
        if: inputs.build_id != '' && inputs.artifact_size != ''
        shell: bash
        run: |
          echo "::notice::Build artifact: ID=${{ inputs.build_id }}, Size=${{ inputs.artifact_size }} bytes"

      # Special workaround for Linux to enable Electron testing
      - name: üîß Apply Linux Kernel Workaround
        # https://github.com/electron/electron/issues/41066
        if: ${{ runner.os == 'Linux' }}
        shell: bash
        run: sudo sysctl -q -w kernel.apparmor_restrict_unprivileged_userns=0

      # Prepare the test applications once - new approach
      - name: üèóÔ∏è Prepare Test Applications
        shell: bash
        run: |
          # Generate build filters based on scenarios
          BUILD_FILTERS=""
          FORGE_FILTERS=""
          NON_FORGE_FILTERS=""
          IS_WINDOWS_FORGE=$([[ "${{ runner.os }}" == "Windows" && "${{ inputs.scenario }}" == *"forge"* ]] && echo "true" || echo "false")

          echo "Is Windows Forge: $IS_WINDOWS_FORGE"

          # Debug Windows environment
          if [[ "${{ runner.os }}" == "Windows" ]]; then
            echo "Windows environment detected - dumping environment for debugging"
            echo "Node.js version: $(node --version)"
            echo "NPM version: $(npm --version)"
            echo "PNPM version: $(pnpm --version)"
            echo "Current directory: $(pwd)"
            echo "Checking if mkdir -p works:"
            mkdir -p test-dir && echo "SUCCESS" || echo "FAILURE"
            echo "Testing Node.js fs.mkdirSync:"
            node -e "require('fs').mkdirSync('test-dir2', { recursive: true }); console.log('SUCCESS');" || echo "FAILURE"
            echo "Testing directory creation complete"
          fi

          IFS=',' read -ra SCENARIOS <<< "${{ inputs.scenario }}"
          for SCENARIO in "${SCENARIOS[@]}"; do
            TRIMMED_SCENARIO=$(echo $SCENARIO | xargs)

            if [[ "$IS_WINDOWS_FORGE" == "true" && "$TRIMMED_SCENARIO" == "forge" ]]; then
              # For Windows forge builds, we'll handle them separately
              FORGE_FILTERS="$FORGE_FILTERS --filter=example-${TRIMMED_SCENARIO}-*"
            else
              # For all other builds, we'll run them in parallel
              NON_FORGE_FILTERS="$NON_FORGE_FILTERS --filter=example-${TRIMMED_SCENARIO}-*"
            fi
          done

          # Build non-forge apps in parallel (if any)
          if [[ -n "$NON_FORGE_FILTERS" ]]; then
            echo "Building non-forge apps with filters: $NON_FORGE_FILTERS"
            pnpm exec turbo run ${{ inputs.build-command }} $NON_FORGE_FILTERS --only --parallel
          fi

          # Build forge apps sequentially on Windows (if any)
          if [[ "$IS_WINDOWS_FORGE" == "true" && -n "$FORGE_FILTERS" ]]; then
            echo "Building Windows forge apps sequentially with filters: $FORGE_FILTERS"
            # Split the forge filters and run one by one
            IFS=' ' read -ra FILTER_PARTS <<< "$FORGE_FILTERS"
            for FILTER in "${FILTER_PARTS[@]}"; do
              if [[ "$FILTER" == "--filter=example-forge-"* ]]; then
                echo "Building: $FILTER"
                pnpm exec turbo run ${{ inputs.build-command }} $FILTER --only
              fi
            done
          elif [[ -n "$FORGE_FILTERS" ]]; then
            # For non-Windows, build forge apps in parallel
            echo "Building forge apps with filters: $FORGE_FILTERS"
            pnpm exec turbo run ${{ inputs.build-command }} $FORGE_FILTERS --only --parallel
          fi

          # Then prepare the test apps for all tests
          cd e2e && pnpm run prepare-apps

      # Run tests based on the scenario and type inputs
      - name: üß™ Execute E2E Tests
        shell: bash
        env:
          # Set environment variables for testing
          PRESERVE_TEMP_DIR: 'true'
          # Set MAC_UNIVERSAL flag if we're using the mac-universal build command
          MAC_UNIVERSAL: ${{ contains(inputs.build-command, 'mac-universal') && 'true' || '' }}
          # Add DEBUG for more verbose output
          DEBUG: 'wdio-electron-service*'
        run: |
          cd e2e

          # Log environment for debugging
          echo "Environment: MAC_UNIVERSAL=$MAC_UNIVERSAL, build-command=${{ inputs.build-command }}"

          # Generate test execution command based on the scenario and type
          if [[ "${{ inputs.scenario }}" == *","* ]]; then
            # Multiple scenarios
            IFS=',' read -ra SCENARIOS <<< "${{ inputs.scenario }}"

            for SCENARIO in "${SCENARIOS[@]}"; do
              TRIMMED_SCENARIO=$(echo $SCENARIO | xargs)

              if [[ "${{ inputs.type }}" == "*" ]]; then
                # Run both ESM and CJS tests
                pnpm run test:${TRIMMED_SCENARIO}:cjs
                pnpm run test:${TRIMMED_SCENARIO}:esm
              else
                # Run specific module type test
                pnpm run test:${TRIMMED_SCENARIO}:${{ inputs.type }}
              fi
            done
          else
            # Single scenario
            if [[ "${{ inputs.scenario }}" == "no-binary" ]]; then
              if [[ "${{ inputs.type }}" == "*" ]]; then
                # Run both ESM and CJS tests for no-binary
                pnpm run test:no-binary:cjs
                pnpm run test:no-binary:esm
              else
                # Run specific module type test for no-binary
                pnpm run test:no-binary:${{ inputs.type }}
              fi
            elif [[ "${{ inputs.scenario }}" == "builder" ]]; then
              if [[ "${{ inputs.type }}" == "*" ]]; then
                # Run both ESM and CJS tests for builder
                pnpm run test:builder:cjs
                pnpm run test:builder:esm
              else
                # Run specific module type test for builder
                pnpm run test:builder:${{ inputs.type }}
              fi
            elif [[ "${{ inputs.scenario }}" == "forge" ]]; then
              if [[ "${{ inputs.type }}" == "*" ]]; then
                # Run both ESM and CJS tests for forge
                pnpm run test:forge:cjs
                pnpm run test:forge:esm
              else
                # Run specific module type test for forge
                pnpm run test:forge:${{ inputs.type }}
              fi
            fi
          fi

      # Show logs on failure to help with debugging
      - name: üêõ Show Test Logs on Failure
        shell: bash
        if: failure()
        run: cd e2e && pnpm run cat-logs

      # Upload logs as artifacts on failure for later analysis
      # This helps debug issues without cluttering the GitHub Actions console
      - name: üì¶ Upload Test Logs on Failure
        uses: ./.github/workflows/actions/upload-archive
        if: failure()
        with:
          name: e2e-logs-${{ inputs.os }}${{ contains(inputs.build-command, 'mac-universal') && '-u' || '' }}-${{ inputs.scenario }}${{ inputs.type != '*' && format('-{0}',inputs.type) || '' }}
          output: e2e-logs-${{ inputs.os }}${{ contains(inputs.build-command, 'mac-universal') && '-u' || '' }}-${{ inputs.scenario }}${{ inputs.type != '*' && format('-{0}',inputs.type) || '' }}.zip
          paths: e2e/logs

      # Clean up temp directories after tests complete
      - name: üßπ Clean Up Temporary Directories
        shell: bash
        if: always()
        run: cd e2e && pnpm run clean:temp-dirs

      # Provide an interactive debugging session on failure
      - name: üêõ Debug Build on Failure
        uses: stateful/vscode-server-action@v1.1.0
        if: failure()
        with:
          timeout: '180000'
