name: E2E Tests
description: 'Runs end-to-end tests across different scenarios and JavaScript module types'

on:
  workflow_call:
    # Make this a reusable workflow, no value needed
    # https://docs.github.com/en/actions/using-workflows/reusing-workflows
    inputs:
      os:
        description: 'Operating system to run tests on'
        required: true
        type: string
      node-version:
        description: 'Node.js version to use for testing'
        required: true
        type: string
      build-command:
        description: 'Build command for test applications (build or build:mac-universal)'
        type: string
        default: 'build'
      scenario:
        description: 'Test scenario (forge, builder, or no-binary)'
        required: true
        type: string
      type:
        description: 'JavaScript module type (esm, cjs, or * for both)'
        type: string
        default: '*'
      build_id:
        description: 'Build ID from the build job'
        type: string
        required: false
      artifact_size:
        description: 'Size of the build artifact in bytes'
        type: string
        required: false
      cache_key:
        description: 'Cache key to use for downloading artifacts'
        type: string
        required: false

env:
  TURBO_TELEMETRY_DISABLED: 1

jobs:
  # This job runs E2E tests for a specific combination of:
  # - Operating system (Linux, Windows, macOS)
  # - Test scenario (builder, forge, no-binary)
  # - Module type (ESM, CJS, or both)
  e2e:
    name: E2E Tests
    runs-on: ${{ inputs.os }}
    continue-on-error: true
    strategy:
      # Continue with other tests even if one fails
      fail-fast: false
    steps:
      # Standard checkout with SSH key for private repositories
      - name: üë∑ Checkout Repository
        uses: actions/checkout@v4
        with:
          ssh-key: ${{ secrets.DEPLOY_KEY }}

      # Set up Node.js and PNPM using the reusable action
      - name: üõ†Ô∏è Setup Development Environment
        uses: ./.github/workflows/actions/setup-workspace
        with:
          node-version: ${{ inputs.node-version }}

      # Download the pre-built packages from the build job
      # This ensures all tests use the same build artifacts
      - name: üì¶ Download Build Artifacts
        uses: ./.github/workflows/actions/download-archive
        with:
          name: wdio-electron-service
          path: wdio-electron-service-build
          filename: artifact.zip
          cache_key_prefix: wdio-electron-build
          exact_cache_key: ${{ inputs.cache_key || github.run_id && format('{0}-{1}-{2}-{3}{4}', 'Linux', 'wdio-electron-build', 'wdio-electron-service', github.run_id, github.run_attempt > 1 && format('-rerun{0}', github.run_attempt) || '') || '' }}

      # Verify the downloaded build artifacts
      - name: üîç Verify Downloaded Artifacts
        shell: bash
        run: |
          echo "=============== VERIFYING BUILD ARTIFACTS ==============="
          echo "Artifact directory contents:"
          ls -la wdio-electron-service-build

          # Check if packaged-service exists
          if [ -d "wdio-electron-service-build/packaged-service" ]; then
            echo "‚úÖ Found packaged-service directory"
            echo "Contents of packaged-service directory:"
            ls -la wdio-electron-service-build/packaged-service
          else
            echo "‚ùå packaged-service directory not found"
            echo "Creating packaged-service directory for debugging:"
            mkdir -p wdio-electron-service-build/packaged-service
          fi

          # Check for dist directories
          if [ -d "wdio-electron-service-build/packages" ]; then
            echo "‚úÖ Found packages directory"
            echo "Contents of packages directory:"
            ls -la wdio-electron-service-build/packages
          else
            echo "‚ùå packages directory not found"
          fi

      # Package service locally if not found in build artifacts
      - name: üì¶ Create Service Package Locally
        shell: bash
        id: local-package-service
        if: ${{ success() }}
        run: |
          # Check if packaged-service directory exists and has a .tgz file
          if [ -d "wdio-electron-service-build/packaged-service" ]; then
            SERVICE_PACKAGE=$(find wdio-electron-service-build/packaged-service -name "wdio-electron-service-*.tgz" 2>/dev/null | head -n 1)
            if [ -n "$SERVICE_PACKAGE" ]; then
              echo "‚úÖ Using service package from build artifacts: $SERVICE_PACKAGE"
              echo "WDIO_SERVICE_TARBALL=$(pwd)/$SERVICE_PACKAGE" >> $GITHUB_ENV
              echo "USE_ARTIFACT_SERVICE=true" >> $GITHUB_ENV
              echo "SKIP_SERVICE_PACKING=true" >> $GITHUB_ENV

              echo "Installing service package in example apps..."
              # Get the active scenario and module type
              IFS=',' read -ra SCENARIOS <<< "${{ inputs.scenario }}"
              MODULE_TYPE="${{ inputs.type }}"

              for SCENARIO in "${SCENARIOS[@]}"; do
                TRIMMED_SCENARIO=$(echo $SCENARIO | xargs)

                if [[ "$MODULE_TYPE" == "*" ]]; then
                  # Both ESM and CJS need to be installed
                  APP_DIRS=("apps/${TRIMMED_SCENARIO}-esm" "apps/${TRIMMED_SCENARIO}-cjs")
                else
                  # Only install for the specific module type
                  APP_DIRS=("apps/${TRIMMED_SCENARIO}-${MODULE_TYPE}")
                fi

                for APP_DIR in "${APP_DIRS[@]}"; do
                  if [ -d "$APP_DIR" ]; then
                    echo "Installing service package in $APP_DIR..."
                    cd "$APP_DIR"
                    pnpm install "$(pwd)/../../$SERVICE_PACKAGE" --no-lockfile
                    cd ../..
                  else
                    echo "Skipping non-existent app directory: $APP_DIR"
                  fi
                done
              done

              exit 0
            fi
          fi

          echo "‚ùå Service package not found in build artifacts. Creating locally..."

          # Create a local package
          mkdir -p local-service-package
          cd packages/wdio-electron-service
          echo "Running pnpm pack in $(pwd)"
          PACKAGE_FILE=$(pnpm pack | tail -n 1)

          if [ -f "$PACKAGE_FILE" ]; then
            echo "‚úÖ Successfully created package: $PACKAGE_FILE"
            # Move the package to the shared directory
            mv "$PACKAGE_FILE" ../../local-service-package/
            cd ../..
            echo "WDIO_SERVICE_TARBALL=$(pwd)/local-service-package/$PACKAGE_FILE" >> $GITHUB_ENV
            echo "USE_ARTIFACT_SERVICE=true" >> $GITHUB_ENV
            echo "SKIP_SERVICE_PACKING=true" >> $GITHUB_ENV
            echo "Local service package created at: $(pwd)/local-service-package/$PACKAGE_FILE"
            ls -la local-service-package
          else
            echo "‚ùå Failed to create local service package"
            cd ../..
            echo "USE_ARTIFACT_SERVICE=false" >> $GITHUB_ENV
            echo "SKIP_SERVICE_PACKING=false" >> $GITHUB_ENV
          fi

      # Display build information if available
      - name: üìä Show Build Information
        if: inputs.build_id != '' && inputs.artifact_size != ''
        shell: bash
        run: |
          echo "::notice::Build artifact: ID=${{ inputs.build_id }}, Size=${{ inputs.artifact_size }} bytes"

      # Special workaround for Linux to enable Electron testing
      - name: üîß Apply Linux Kernel Workaround
        # https://github.com/electron/electron/issues/41066
        if: ${{ runner.os == 'Linux' }}
        shell: bash
        run: sudo sysctl -q -w kernel.apparmor_restrict_unprivileged_userns=0

      # Prepare the test applications once - new approach
      - name: üèóÔ∏è Prepare Test Applications
        shell: bash
        env:
          # Preserve temp directories between steps
          PRESERVE_TEMP_DIR: 'true'
          # Enable more detailed debug logging
          DEBUG: 'wdio-electron-service*'
          # Use the pre-built service from the build job
          USE_ARTIFACT_SERVICE: ${{ env.USE_ARTIFACT_SERVICE || 'true' }}
          # Pass through service tarball path if available
          WDIO_SERVICE_TARBALL: ${{ env.WDIO_SERVICE_TARBALL || '' }}
        timeout-minutes: 15
        run: |
          echo "Preparing test applications for scenario: ${{ inputs.scenario }}, module type: ${{ inputs.type }}"
          cd e2e

          # Build command with optional scenario and module type filters
          PREPARE_CMD="pnpm run prepare-apps --timeout=600000"

          # Add scenario filter if provided
          if [[ -n "${{ inputs.scenario }}" && "${{ inputs.scenario }}" != "all" ]]; then
            PREPARE_CMD+=" --scenario=${{ inputs.scenario }}"
          fi

          # Add module type filter if provided
          if [[ -n "${{ inputs.type }}" && "${{ inputs.type }}" != "all" ]]; then
            PREPARE_CMD+=" --module-type=${{ inputs.type }}"
          fi

          echo "Running: $PREPARE_CMD"
          eval "$PREPARE_CMD"

      # Run tests based on the scenario and type inputs
      - name: üß™ Execute E2E Tests
        shell: bash
        id: run_tests
        env:
          # Set environment variables for testing
          PRESERVE_TEMP_DIR: 'true'
          # Pass through test apps variables from previous steps
          WDIO_TEST_APPS_PREPARED: ${{ env.WDIO_TEST_APPS_PREPARED }}
          WDIO_TEST_APPS_DIR: ${{ env.WDIO_TEST_APPS_DIR }}
          SUITE_SETUP_DONE: 'true'
          # Set MAC_UNIVERSAL flag if we're using the mac-universal build command
          MAC_UNIVERSAL: ${{ contains(inputs.build-command, 'mac-universal') && 'true' || '' }}
          # Add DEBUG for more verbose output
          DEBUG: 'wdio-electron-service*'
        run: |
          cd e2e

          # Log environment for debugging
          echo "Environment: MAC_UNIVERSAL=$MAC_UNIVERSAL, build-command=${{ inputs.build-command }}, ELECTRON_CACHE=$ELECTRON_CACHE"
          echo "Test apps: WDIO_TEST_APPS_PREPARED=$WDIO_TEST_APPS_PREPARED, WDIO_TEST_APPS_DIR=$WDIO_TEST_APPS_DIR, SUITE_SETUP_DONE=$SUITE_SETUP_DONE"

          # Generate test execution command based on the scenario and type
          if [[ "${{ inputs.scenario }}" == *","* ]]; then
            # Multiple scenarios
            IFS=',' read -ra SCENARIOS <<< "${{ inputs.scenario }}"

            for SCENARIO in "${SCENARIOS[@]}"; do
              TRIMMED_SCENARIO=$(echo $SCENARIO | xargs)

              if [[ "${{ inputs.type }}" == "*" ]]; then
                # Run both ESM and CJS tests
                pnpm run test:${TRIMMED_SCENARIO}:cjs
                pnpm run test:${TRIMMED_SCENARIO}:esm
              else
                # Run specific module type test
                pnpm run test:${TRIMMED_SCENARIO}:${{ inputs.type }}
              fi
            done
          else
            # Single scenario
            if [[ "${{ inputs.scenario }}" == "no-binary" ]]; then
              if [[ "${{ inputs.type }}" == "*" ]]; then
                # Run both ESM and CJS tests for no-binary
                pnpm run test:no-binary:cjs
                pnpm run test:no-binary:esm
              else
                # Run specific module type test for no-binary
                pnpm run test:no-binary:${{ inputs.type }}
              fi
            elif [[ "${{ inputs.scenario }}" == "builder" ]]; then
              if [[ "${{ inputs.type }}" == "*" ]]; then
                # Run both ESM and CJS tests for builder
                pnpm run test:builder:cjs
                pnpm run test:builder:esm
              else
                # Run specific module type test for builder
                pnpm run test:builder:${{ inputs.type }}
              fi
            elif [[ "${{ inputs.scenario }}" == "forge" ]]; then
              if [[ "${{ inputs.type }}" == "*" ]]; then
                # Run both ESM and CJS tests for forge
                pnpm run test:forge:cjs
                pnpm run test:forge:esm
              else
                # Run specific module type test for forge
                pnpm run test:forge:${{ inputs.type }}
              fi
            fi
          fi

      # Show logs on failure to help with debugging
      - name: üêõ Show Test Logs on Failure
        shell: bash
        if: failure()
        run: cd e2e && pnpm run cat-logs

      # Upload logs as artifacts on failure for later analysis
      # This helps debug issues without cluttering the GitHub Actions console
      - name: üì¶ Upload Test Logs on Failure
        uses: ./.github/workflows/actions/upload-archive
        if: failure()
        with:
          name: e2e-logs-${{ inputs.os }}${{ contains(inputs.build-command, 'mac-universal') && '-u' || '' }}-${{ inputs.scenario }}${{ inputs.type != '*' && format('-{0}',inputs.type) || '' }}
          output: e2e-logs-${{ inputs.os }}${{ contains(inputs.build-command, 'mac-universal') && '-u' || '' }}-${{ inputs.scenario }}${{ inputs.type != '*' && format('-{0}',inputs.type) || '' }}.zip
          paths: e2e/logs

      # Clean up temp directories after tests complete
      - name: üßπ Clean Up Temporary Directories
        shell: bash
        if: always()
        run: cd e2e && pnpm run clean:temp-dirs

      # Provide an interactive debugging session on failure
      - name: üêõ Debug Build on Failure
        uses: stateful/vscode-server-action@v1.1.0
        if: failure()
        with:
          timeout: '180000'
